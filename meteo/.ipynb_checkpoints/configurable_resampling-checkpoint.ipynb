{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e10c7885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsampling Y is M\n",
      "downsampling Y is Y\n",
      "upsampling M is 10D\n",
      "downsampling M is Y\n",
      "upsampling 10D is H\n",
      "downsampling 10D is W\n",
      "upsampling W is D\n",
      "downsampling W is 10D\n",
      "upsampling D is H\n",
      "downsampling D is W\n",
      "upsampling H is H\n",
      "downsampling H is D\n"
     ]
    }
   ],
   "source": [
    "import xarray as xs\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json\n",
    "\n",
    "def _convert_relativedelta_to_str_isoduration(delta):\n",
    "    iso_8601_duration = \"P\"\n",
    "    if delta.years:\n",
    "        iso_8601_duration += \"{}Y\".format(delta.years)\n",
    "    if delta.months:\n",
    "        iso_8601_duration += \"{}M\".format(delta.months)\n",
    "    if delta.days:\n",
    "        iso_8601_duration += \"{}D\".format(delta.days)\n",
    "    if delta.hours or delta.minutes or delta.seconds:\n",
    "        iso_8601_duration += \"T\"\n",
    "        if delta.hours:\n",
    "            iso_8601_duration += \"{}H\".format(delta.hours)\n",
    "        if delta.minutes:\n",
    "            iso_8601_duration += \"{}M\".format(delta.minutes)\n",
    "        if delta.seconds:\n",
    "            iso_8601_duration += \"{}S\".format(delta.seconds)\n",
    "    return iso_8601_duration\n",
    "\n",
    "datasets_groups = {\n",
    "    'RR DAILY': ['RR', 'RR_DAILY_VALUES'], \n",
    "    'RR DECADE': ['RR', 'RR_DECADE_VALUES'], \n",
    "    'RR MONTHLY': ['RR', 'RR_MONTHLY_VALUES'],\n",
    "    'RR YEARLY': ['RR', 'RR_YEARLY_VALUES'], \n",
    "    'TN DAILY': ['TN', 'TN_DAILY_VALUES'], \n",
    "    'TN DECADE': ['TN', 'TN_DECADE_VALUES'], \n",
    "    'TN MONTHLY': ['TN', 'TN_MONTHLY_VALUES'],\n",
    "    'TN YEARLY': ['TN', 'TN_YEARLY_VALUES'], \n",
    "    'TM DAILY': ['TM', 'TM_DAILY_VALUES'], \n",
    "    'TM DECADE': ['TM', 'TM_DECADE_VALUES'], \n",
    "    'TM MONTHLY': ['TM', 'TM_MONTHLY_VALUES'],\n",
    "    'TM YEARLY': ['TM', 'TM_YEARLY_VALUES'], \n",
    "    'TX DAILY': ['TX', 'TX_DAILY_VALUES'], \n",
    "    'TX DECADE': ['TX', 'TX_DECADE_VALUES'], \n",
    "    'TX MONTHLY': ['TX', 'TX_MONTHLY_VALUES'],\n",
    "    'TX YEARLY': ['TX', 'TX_YEARLY_VALUES'], \n",
    "}\n",
    "\n",
    "sampling_groups = {'YEARLY': 'Y', 'MONTHLY': 'M', 'DECADAL': '10D', 'WEEKLY': 'W', 'DAILY': 'D', 'HOURLY': 'H'}\n",
    "function_groups = {'MIN': 'min', 'MAX': 'max', 'MEAN': 'mean', 'SUM': 'sum'}\n",
    "\n",
    "def upsampling_period(sampling_period):\n",
    "    vals = [ v for v in sampling_groups.values()]\n",
    "    idx = 0\n",
    "    for v in vals:\n",
    "        if sampling_period[-1]==v:\n",
    "            return vals[idx+1] if idx+1<len(vals) else vals[len(vals)-1]\n",
    "        idx = idx +1 \n",
    "        \n",
    "def downsampling_period(sampling_period):\n",
    "    vals = [ v for v in sampling_groups.values()]\n",
    "    idx = 0\n",
    "    for v in vals:\n",
    "        if sampling_period[-1]==v:\n",
    "            return vals[idx-1] if idx-1>=0 else vals[0]\n",
    "        idx = idx +1 \n",
    "\n",
    "def sampling_group(iso_period):\n",
    "    vals = [ v for v in sampling_groups.values()]\n",
    "    if iso_period[0] == 'P' and iso_period[-1] in sampling_groups.values():\n",
    "        return iso_period[1:]\n",
    "    raise Exception('invalid sampling period, should be a P<int>(Y|M|W|D|H) iso8061 format representation')\n",
    "\n",
    "for v in sampling_groups.values():\n",
    "    print(f'upsampling {v} is {upsampling_period(v)}')\n",
    "    print(f'downsampling {v} is {downsampling_period(v)}')\n",
    "\n",
    "def compute_sampling_freq(variable):\n",
    "    timesv = variable.time.values\n",
    "\n",
    "    tsv_1 = datetime.strptime(str(timesv[1]).split('.')[0], \"%Y-%m-%dT%H:%M:%S\")\n",
    "    tsv_2 = datetime.strptime(str(timesv[0]).split('.')[0], \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "    timedeltasv = relativedelta(tsv_1, tsv_2)\n",
    "\n",
    "    return _convert_relativedelta_to_str_isoduration(timedeltasv)\n",
    "\n",
    "\n",
    "def dump_as_json(values):\n",
    "    return json.dumps({\n",
    "                    'infos': values.attrs,\n",
    "                    'data': [\n",
    "                        ['%sZ' % str(v.time.values).split('.')[0],\n",
    "                         str(v.values),\n",
    "                         ]\n",
    "                        for v in values\n",
    "                    ],\n",
    "                }, indent=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b476e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440f4c6aaeb44d00ae1582e564966177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='from_dataset', options=('RR DAILY', 'RR DECADE', 'RR MONTHLY', 'RR…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8af0b89e18c4fbb94fd6805c2810552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='from_function', options=('MIN', 'MAX', 'MEAN', 'SUM'), value='MIN'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1569609f4f7343f38a09069bbfbcd38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='from_sampling', options=('YEARLY', 'MONTHLY', 'DECADAL', 'WEEKLY',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Dropdown, interact\n",
    "\n",
    "datasets_groups_keys = [v for v in datasets_groups.keys()]\n",
    "fromDatasetW = Dropdown(options=datasets_groups_keys, value=datasets_groups_keys[0])\n",
    "\n",
    "sampling_groups_keys = [v for v in sampling_groups.keys()]\n",
    "fromSamplingW = Dropdown(options=sampling_groups_keys, value=sampling_groups_keys[0])\n",
    "\n",
    "function_groups_keys = [v for v in function_groups.keys()]\n",
    "fromFunctionW = Dropdown(options=function_groups_keys, value=function_groups_keys[0])\n",
    "\n",
    "@interact(from_dataset = fromDatasetW)\n",
    "def handle_dataset(from_dataset):\n",
    "    global ds\n",
    "    global varname\n",
    "    global from_freq\n",
    "    try:\n",
    "        print(from_dataset)\n",
    "        group, varname = datasets_groups[from_dataset]\n",
    "        print(f'group [{group}] : {varname}')\n",
    "        filename=f\"./data/2022/{group}/{varname}.nc\"\n",
    "        print(filename)\n",
    "        ds = xs.open_mfdataset([filename])\n",
    "        print(ds)\n",
    "        print(ds[varname])\n",
    "        from_freq = compute_sampling_freq(ds[varname])\n",
    "        print(f'\\n\\nsampling frequency for {varname} is {from_freq}\\n\\n')\n",
    "        \n",
    "    except:\n",
    "        print('oops')\n",
    "        \n",
    "@interact(from_function = fromFunctionW)\n",
    "def handle_function(from_function):\n",
    "    print(from_function)\n",
    "    global funct\n",
    "    funct = from_function\n",
    "    \n",
    "@interact(from_sampling = fromSamplingW)\n",
    "def handle_freq(from_sampling):\n",
    "    global values\n",
    "    try:\n",
    "        print(from_sampling)\n",
    "        print(sampling_groups[from_sampling])\n",
    "        print(f'{varname} to be resampled from {from_freq} to {sampling_groups[from_sampling]} frequency')\n",
    "        \n",
    "        print(f'was : {dump_as_json(ds[varname])}')\n",
    "\n",
    "        if funct == 'MEAN':\n",
    "            result = ds[varname].resample(time=sampling_groups[from_sampling]).mean()\n",
    "        elif funct == 'MIN':\n",
    "            result = ds[varname].resample(time=sampling_groups[from_sampling]).min()\n",
    "        elif funct == 'MAX':\n",
    "            result = ds[varname].resample(time=sampling_groups[from_sampling]).max()\n",
    "        elif funct == 'SUM':\n",
    "            result = ds[varname].resample(time=sampling_groups[from_sampling]).sum()\n",
    "        else:\n",
    "            raise Exception(f'undefined function {funct}')\n",
    "            \n",
    "        print(f'now : {dump_as_json(result)}')\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
